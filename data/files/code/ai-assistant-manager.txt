# ai-assistant-manager

## prompt_test.py

### Summary

The code defines a test function `test_get_prompt()` that checks if the `get_prompt()` function correctly retrieves a prompt from a specified path (`SAMPLE_PROMPT_PATH`). It asserts that the returned prompt is a string and includes the current date in its text.

```py
from datetime import datetime

from .prompt import SAMPLE_PROMPT_PATH, get_prompt


def test_get_prompt():
    current_date = datetime.today().date().isoformat()

    prompt = get_prompt(prompt_path=SAMPLE_PROMPT_PATH)
    assert isinstance(prompt, str)
    assert current_date in prompt

```

## exporter_test.py

### Summary

The code consists of unit tests for two functions: `does_data_exist` and `create_dir`.

1. **test_does_data_exist**: This test verifies that the `does_data_exist` function returns `True` when the specified file exists, using a mocked version of `os.path.exists`.

2. **test_create_dir_data_exists**: This test checks that `create_dir` does not create a directory if the data already exists (i.e., `does_data_exist` returns `True`). It uses a mock for `does_data_exist` to simulate this scenario and ensures that `os.makedirs` is not called.

3. **test_create_dir_data_does_not_exist**: This test ensures that `create_dir` successfully creates a directory when data does not exist (i.e., `does_data_exist` returns `False`). It verifies that `os.makedirs` is called once with the correct parameters.

Overall, the code uses mocking to test the behavior of directory creation based on the existence of data.

```py
from unittest.mock import Mock, patch

from .exporter import create_dir, does_data_exist


def test_does_data_exist():
    """
    Test that does_data_exist returns True when the file exists.
    """
    file_path = Mock(return_value="path/to/file")

    with patch("os.path.exists", return_value=True):
        result = does_data_exist(file_path)

    assert result


@patch("ai_assistant_manager.exporters.exporter.does_data_exist")
def test_create_dir_data_exists(mock_does_data_exist: Mock):
    """
    Test that create_dir does not create a directory if data already exists.
    """
    mock_does_data_exist.return_value = True

    with patch("os.makedirs") as mock_makedirs:
        create_dir("dir/path", "file/path")

    mock_makedirs.assert_not_called()


@patch("ai_assistant_manager.exporters.exporter.does_data_exist")
def test_create_dir_data_does_not_exist(mock_does_data_exist: Mock):
    """
    Test that create_dir creates a directory if data does not exist.
    """
    mock_does_data_exist.return_value = False

    with patch("os.makedirs") as mock_makedirs:
        create_dir("dir/path", "file/path")

    mock_makedirs.assert_called_once_with("dir/path", exist_ok=True)

```

## encoding.py

### Summary

The code defines a constant `UTF_8` and assigns it the string value "utf-8", which represents the UTF-8 character encoding.

```py
UTF_8 = "utf-8"

```

## timer_test.py

### Summary

This code defines a unit test for a `timer` decorator, which is intended to log the execution time of a function. The test creates a dummy function decorated with `@timer("Test function")`. It uses mocking to check that the logger is called correctly when the dummy function is invoked. Specifically, it asserts that the logger's `debug` method is called once with a message containing "Test function: completed in".

```py
from unittest.mock import patch

from .timer import timer


def test_timer_decorator():
    """
    Test that the timer decorator logs the correct message when the decorated function is called.
    """

    @timer("Test function")
    def dummy_function():
        pass

    with patch("ai_assistant_manager.timer.timer.logger") as mock_logger:
        dummy_function()

    # Ensure the logger is called once with the expected message
    mock_logger.debug.assert_called_once()
    assert "Test function: completed in" in mock_logger.debug.call_args[0][0]

```

## timer.py

### Summary

The provided code defines a decorator named `timer` that measures and logs the execution time of a function. When the decorated function is called, it records the start time, executes the function, and then records the end time. It calculates the elapsed time and logs a debug message with this information along with a custom message. The `loguru` library is used for logging, and the decorator preserves the original function's metadata using `functools.wraps`.

```py
import time
from functools import wraps

from loguru import logger


def timer(message: str):
    """
    Decorator to measure the execution time of a function and log it.

    :param message: The message to include in the log.
    :return: The decorator function.
    """

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            end_time = time.time()
            elapsed_time = round(end_time - start_time, 4)
            logger.debug(f"{message}: completed in {elapsed_time} seconds")
            return result

        return wrapper

    return decorator

```

## exporter.py

### Summary

The code defines two functions for handling a data file and its associated directory:

1. **does_data_exist(file_path: str) -> bool**: Checks if a data file exists at the specified path and returns `True` if it does, otherwise `False`.

2. **create_dir(dir_path: str, file_path: str)**: Creates a directory at the specified path only if the data file does not already exist, logging the action.

The code utilizes the `os` module to perform file system operations and `loguru` for logging.

```py
import os

from loguru import logger


def does_data_exist(file_path: str) -> bool:
    """
    Check if the data file exists at the given file path.

    This function is used to determine whether a specific data file is already present,
    which helps in deciding whether to create a new directory or not.

    :param file_path: The path to the data file.
    :return: True if the file exists, False otherwise.
    """
    return os.path.exists(file_path)


def create_dir(dir_path: str, file_path: str):
    """
    Create a directory if the data file does not exist.

    This function ensures that the directory structure is in place before any data files are created.
    It prevents redundant directory creation if the data file already exists.

    :param dir_path: The path to the directory to create.
    :param file_path: The path to the data file to check.
    """
    if not does_data_exist(file_path):
        logger.info(f"Creating data dir path: {dir_path}")
        os.makedirs(dir_path, exist_ok=True)

```

## directory_exporter.py

### Summary

The `DirectoryExporter` class is designed to export data from a specified directory into a JSON file. Upon initialization, it accepts a directory path.

### Key Methods:

- **export()**: Checks if the JSON file for the directory already exists; if not, it creates the necessary directories and writes the data to the JSON file.
- **write_data()**: Loads data from the directory, converts it to a dictionary format, and writes it as JSON to a file.
- **load()**: Reads all files in the directory and returns a list of `ContentData` objects.
- **file_load(filename)**: Loads data from a single file, extracting an ID, title, body, and date, then returns a `ContentData` object.
- **get_dir_path()**: Constructs and returns the full path to the target directory.
- **get_file_path()**: Creates the complete path for the JSON export file.
- **get_data_dir_path()**: Provides the path to the directory containing the data files.

### Logging:

Utilizes the `loguru` logger to provide information about the export process.

Overall, this class is responsible for managing the exporting of content data from a specified directory into a properly formatted JSON file while ensuring that existing data is not overwritten.

```py
import json
import os
from dataclasses import asdict

from dateutil import parser
from loguru import logger

from ai_assistant_manager.encoding import UTF_8
from ai_assistant_manager.env_variables import ENV_VARIABLES

from ..content_data import ContentData
from ..exporter import create_dir, does_data_exist


class DirectoryExporter:
    """
    Handles exporting data from a directory to a JSON file.
    """

    def __init__(self, directory: str):
        """
        Initialize the DirectoryExporter with the target directory.

        :param directory: The directory to export data from.
        """
        self.directory = directory

    def export(self):
        """
        Export the directory data to a JSON file if it doesn't already exist.
        """
        if does_data_exist(self.get_file_path()):
            logger.info(f"Directory '{self.directory}' data exits. Skipping export.")
            return

        logger.info(f"Exporting directory '{self.directory}' data")
        create_dir(self.get_dir_path(), self.get_file_path())
        self.write_data()

    def write_data(self):
        """
        Write the loaded data to a JSON file.
        """
        data = self.load()

        data_as_dicts = {data.title: asdict(data) for data in data}
        json_data = json.dumps(data_as_dicts)

        with open(self.get_file_path(), "w", encoding=UTF_8) as file:
            file.write(json_data)

        logger.info(f"Directory '{self.directory}' data written to file: {self.get_file_path()}")

    def load(self):
        """
        Load data from files in the directory.

        :return: A list of ContentData objects.
        """
        files = os.listdir(self.get_data_dir_path())
        return [self.file_load(filename) for filename in files]

    def file_load(self, filename: str) -> ContentData:
        """
        Load data from a single file.

        :param filename: The name of the file to load.
        :return: A ContentData object with the file's data.
        """
        file_id = filename[:3]
        name, _ = os.path.splitext(filename)
        title = name[3:].strip()

        with open(
            os.path.join(self.get_data_dir_path(), filename),
            "r",
            encoding=UTF_8,
        ) as file:
            lines = file.readlines()

        body = "\n".join([line.strip() for line in lines[1:]])

        date = parser.parse(lines[0].strip()).isoformat()

        return ContentData(
            id=file_id,
            title=title,
            body=body,
            date=date,
        )

    def get_dir_path(self) -> str:
        """
        Get the path to the directory.

        :return: The directory path.
        """
        return os.path.join(
            ENV_VARIABLES.bin_dir,
            self.directory,
        )

    def get_file_path(self) -> str:
        """
        Get the path to the JSON file where data will be exported.

        :return: The file path.
        """
        return os.path.join(
            self.get_dir_path(),
            f"{ENV_VARIABLES.data_file_prefix} - {self.directory}.json",
        )

    def get_data_dir_path(self) -> str:
        """
        Get the path to the directory containing the data files.

        :return: The data directory path.
        """
        return os.path.join(ENV_VARIABLES.data_dir, self.directory)

```

## pyproject.toml

### Summary

This code is a configuration file for a Python project called "ai-assistant-manager," which provides tools for managing OpenAI Assistants. It specifies the build system using Hatchling, project metadata (like name, description, author, no, and Python version requirement), and the necessary dependencies for the project. It also includes keywords for discovering the project, development classifiers, and URLs for the repository.

Additionally, it sets up building targets (for source distribution and wheel), a default virtual environment for development, scripts for end-to-end testing and publishing, static analysis configuration, and linting rules for code quality.

```toml
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "ai-assistant-manager"
dynamic = ["version"]
description = "This repository provides tools and services to manage OpenAI Assistants, including creating, listing, and deleting assistants, as well as handling vector stores and retrieval files."
no = { file = "no" }
readme = "README.md"
authors = [{ name = "Justin Beall", email = "jus.beall@gmail.com" }]
requires-python = ">=3.11"
dependencies = ["loguru", "openai", "python-dateutil", "python-dotenv", "twine"]
keywords = [
    "AI",
    "API",
    "artificial intelligence",
    "assistant",
    "automation",
    "chatbot",
    "data science",
    "deep learning",
    "machine learning",
    "management",
    "natural language processing",
    "NLP",
    "openai",
    "python",
    "vector store",
]

classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "no :: OSI Approved :: MIT no",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Topic :: Software Development :: Libraries :: Python Modules",
]

[project.urls]
repository = "https://github.com/DEV3L/open-ai-assistant"

[tool.hatch.version]
path = "setup.cfg"
pattern = "version = (?P<version>\\S+)"

[tool.hatch.build.targets.sdist]
include = ["/ai_assistant_manager"]
artifact = { name = "ai-assistant-manager" }

[tool.hatch.build.targets.wheel]
packages = ["ai_assistant_manager"]
artifact = { name = "ai-assistant-manager" }

[tool.hatch.envs.default]
type = "virtual"
path = ".venv"
dependencies = ["pyright", "pytest", "pytest-cov"]

[tool.hatch.envs.default.scripts]
e2e = "python run_end_to_end.py"
test = "pytest --cache-clear --cov --cov-report lcov --cov-report term"
publish = "rm -rf bin && rm -rf dist && hatch build && twine upload dist/*"

[tool.hatch.envs.hatch-static-analysis]
config-path = "ruff_defaults.toml"

[tool.ruff]
extend = "ruff_defaults.toml"

[tool.ruff.lint.flake8-tidy-imports]
ban-relative-imports = "parents"

```

## files_exporter_test.py

### Summary

The provided code is a set of unit tests for a `FilesExporter` class in a Python application. It utilizes the `pytest` framework along with `unittest.mock` to simulate dependencies.

### Key Components:

1. **Fixture**:

   - `build_exporter`: Creates a `FilesExporter` instance for use in tests.

2. **Tests**:
   - `test_export_data_exists`: Verifies that no directory is created if data already exists.
   - `test_export_data_does_not_exist`: Checks that a directory is created and data is written if it does not exist.
   - `test_write_data`: Tests that the `write_data` method correctly copies a file to the target path.
   - `test_get_dir_path`: Confirms that the method returns the correct directory path.
   - `test_get_file_path`: Ensures the method returns the correct file path.

### Mocking:

- Various functions related to file operations are mocked to isolate the tests from actual file system interactions, allowing for controlled tests on the logic of `FilesExporter`.

### Summary:

Overall, the code tests the functionalities of `FilesExporter`, ensuring it behaves correctly under different scenarios, such as existing data checks and accurate file path retrievals.

```py
from unittest.mock import Mock, patch

import pytest

from ai_assistant_manager.env_variables import ENV_VARIABLES

from .files_exporter import FilesExporter

FILE_NAME = "test_file.txt"
DATA_DIRECTORY = "test_dir"


@pytest.fixture(name="exporter")
def build_exporter() -> FilesExporter:
    """
    Fixture to create a FilesExporter instance for testing.
    """
    return FilesExporter(FILE_NAME, directory=DATA_DIRECTORY)


@patch("ai_assistant_manager.exporters.files.files_exporter.create_dir")
@patch("ai_assistant_manager.exporters.files.files_exporter.does_data_exist")
def test_export_data_exists(mock_does_data_exist: Mock, mock_create_dir: Mock, exporter: FilesExporter) -> None:
    """
    Test that export does not create directory if data already exists.
    """
    mock_does_data_exist.return_value = True

    exporter.export()

    mock_create_dir.assert_not_called()


@patch("ai_assistant_manager.exporters.files.files_exporter.create_dir")
@patch("ai_assistant_manager.exporters.files.files_exporter.does_data_exist")
def test_export_data_does_not_exist(mock_does_data_exist: Mock, mock_create_dir: Mock, exporter: FilesExporter) -> None:
    """
    Test that export creates directory and writes data if data does not exist.
    """
    mock_does_data_exist.return_value = False

    exporter.write_data = Mock()

    exporter.export()

    mock_create_dir.assert_called_once()
    exporter.write_data.assert_called_once()


@patch("ai_assistant_manager.exporters.files.files_exporter.shutil")
def test_write_data(mock_shutil: Mock, exporter: FilesExporter) -> None:
    """
    Test that write_data correctly copies the file to the target path.
    """
    exporter.get_file_path = Mock(return_value="path/to/file")

    exporter.write_data()

    mock_shutil.copy.assert_called_once_with(f"{ENV_VARIABLES.data_dir}/{DATA_DIRECTORY}/{FILE_NAME}", "path/to/file")


def test_get_dir_path(exporter: FilesExporter) -> None:
    """
    Test that get_dir_path returns the correct directory path.
    """
    result = exporter.get_dir_path()

    assert result == f"{ENV_VARIABLES.bin_dir}/{DATA_DIRECTORY}"


def test_get_file_path(exporter: FilesExporter) -> None:
    """
    Test that get_file_path returns the correct file path.
    """
    result = exporter.get_file_path()

    assert result == f"{ENV_VARIABLES.bin_dir}/{DATA_DIRECTORY}/{ENV_VARIABLES.data_file_prefix} - {FILE_NAME}"

```

## assistant_service_test.py

### Summary

The code is a unit test suite for the `AssistantService` class, utilizing the `unittest` framework in Python. It tests the functionality of the `AssistantService` methods for handling assistants and vector stores, including their retrieval, creation, validation, and deletion.

### Test Cases Overview:

1. **Setup**: Mocks a client and initializes the `AssistantService` with a prompt.
2. **Test Assistant ID Retrieval**:
   - Checks if an ID is returned when an assistant exists.
   - Verifies a new assistant is created if none exists.
3. **Test Vector Store ID Retrieval**:
   - Validates IDs are returned for existing vector stores.
4. **Test Vector Store Creation**:
   - Ensures vector stores are created correctly and handles failure scenarios for files.
5. **Test Validation of Vector Stores**:
   - Confirms successful validation returns the correct vector store ID.
6. **Test Retrieval File ID**:
   - Checks for existing retrieval file IDs.
7. **Test Creation of Retrieval Files**:
   - Tests that retrieval files can be created, returning their IDs.
8. **Delete Assistant Methods**:
   - Tests correct deletion behavior with existing assistants and files.
   - Confirms that no deletion occurs if no assistant or files exist.

Overall, the tests use mocks to simulate interactions with a client and verify the expected outcomes without requiring actual services or data.

```py
from unittest import TestCase, mock
from unittest.mock import MagicMock, mock_open, patch

from ..env_variables import ENV_VARIABLES
from .assistant_service import AssistantService


class TestAssistantService(TestCase):
    service: AssistantService
    prompt = "A helpful assistant"

    def setUp(self):
        """
        Set up the test case with a mocked client and an AssistantService instance.
        """
        self.mock_client = MagicMock()
        self.service = AssistantService(self.mock_client, self.prompt)

    def test_get_assistant_id_exists(self):
        """
        Test that get_assistant_id returns the correct ID when the assistant already exists.
        """
        mock_assistant = MagicMock(id="456")
        mock_assistant.name = ENV_VARIABLES.assistant_name
        self.mock_client.assistants_list = MagicMock(
            return_value=[
                mock_assistant,
            ]
        )

        result = self.service.get_assistant_id()

        assert result == "456"
        self.mock_client.assistants_list.assert_called_once()
        self.mock_client.assistants_create.assert_not_called()

    def test_get_assistant_id_not_exists(self):
        """
        Test that get_assistant_id creates a new assistant when it does not exist.
        """
        self.mock_client.assistants_list = MagicMock(return_value=[])

        result = self.service.get_assistant_id()

        assert result == self.mock_client.assistants_create.return_value.id

    def test_get_vector_store_ids_exists(self):
        """
        Test that get_vector_store_ids returns the correct IDs when vector stores already exist.
        """
        self.mock_client.vector_stores_list = MagicMock(
            return_value=[
                MagicMock(filename=f"{ENV_VARIABLES.data_file_prefix} vector store", id="654"),
            ]
        )

        result = self.service.get_vector_store_ids()

        assert result == ["654"]
        self.mock_client.vector_stores_list.assert_called_once()
        self.mock_client.create_vector_stores.assert_not_called()

    def test_create_vector_stores(self):
        """
        Test that create_vector_stores creates vector stores and returns their IDs.
        """
        expected_vector_store_id = "vector_store_id"
        expected_file_ids = ["file1_id", "file2_id"]
        self.mock_client.vector_stores_create.return_value = expected_vector_store_id
        self.mock_client.vector_stores_files.return_value = [
            MagicMock(status="completed"),
        ]

        self.service.get_retrieval_file_ids = lambda: expected_file_ids

        vector_store_ids = self.service.create_vector_stores()

        assert vector_store_ids == [expected_vector_store_id]
        self.mock_client.vector_stores_create.assert_called_with(mock.ANY, expected_file_ids)
        self.mock_client.vector_stores_files.assert_called_with(expected_vector_store_id)

    def test_create_vector_stores_with_failed_files(self):
        """
        Test that create_vector_stores handles failed files correctly.
        """
        expected_vector_store_id = "vector_store_id"
        expected_file_ids = ["file1_id", "file2_id"]
        self.mock_client.vector_stores_create.return_value = expected_vector_store_id
        self.mock_client.vector_stores_files.side_effect = [
            [MagicMock(status="failed", id="abc")],
            lambda: Exception("Failed to create vector store"),
            [MagicMock(status="completed", id="def")],
        ]
        self.mock_client.files_get.return_value = MagicMock(filename="file_name")
        self.service.get_retrieval_file_ids = lambda: expected_file_ids

        mock_os_walk = [("root", None, ["file_name"])]

        with patch("os.walk", return_value=mock_os_walk), patch("builtins.open", mock_open(read_data="data")):
            vector_store_ids = self.service.create_vector_stores()

        assert vector_store_ids == [expected_vector_store_id]
        self.mock_client.vector_stores_file_delete.assert_called_with(expected_vector_store_id, "abc")
        self.mock_client.vector_stores_create.assert_called_with(mock.ANY, expected_file_ids)
        self.mock_client.vector_stores_files.assert_called_with(expected_vector_store_id)

    def test_validate_vector_stores(self):
        """
        Test that _validate_vector_stores returns the correct vector store ID when validation is successful.
        """
        expected_vector_store_id = "vector_store_id"

        self.mock_client.vector_stores_files.return_value = [
            MagicMock(status="completed"),
        ]

        vector_store_id = self.service._validate_vector_stores(expected_vector_store_id)

        assert vector_store_id == expected_vector_store_id

    def test_get_retrieval_file_ids_exists(self):
        """
        Test that get_retrieval_file_ids returns the correct IDs when retrieval files already exist.
        """
        self.mock_client.files_list = MagicMock(
            return_value=[
                MagicMock(filename=f"{ENV_VARIABLES.data_file_prefix} blogs.json", id="456"),
            ]
        )

        result = self.service.get_retrieval_file_ids()

        assert result == ["456"]
        self.mock_client.files_list.assert_called_once()
        self.mock_client.files_create.assert_not_called()

    def test_create_retrieval_files(self):
        """
        Test that create_retrieval_files creates retrieval files and returns their IDs.
        """
        self.mock_client.files_create.return_value.id = "file_id"

        mock_os_walk = [("root", None, ["file1", "file2"])]
        expected_file_ids = ["file_id", "file_id"]

        with patch("os.walk", return_value=mock_os_walk), patch("builtins.open", mock_open(read_data="data")):
            actual_file_ids = self.service.create_retrieval_files()

        assert actual_file_ids == expected_file_ids
        self.mock_client.files_create.assert_called_with(mock.ANY, "assistants")

    # pylint: disable=protected-access
    def test_delete_assistant_with_existing_assistant_and_files(self):
        """
        Test that delete_assistant deletes the assistant and associated files when they exist.
        """
        self.service._find_existing_assistant = MagicMock(return_value="assistant_id")
        self.service._find_existing_vector_stores = MagicMock(return_value=["vs1_id", "vs2_id"])
        self.service._find_existing_retrieval_files = MagicMock(return_value=["file1_id", "file2_id"])

        self.service.delete_assistant()

        self.service._find_existing_assistant.assert_called_once()
        self.service._find_existing_vector_stores.assert_called_once()
        self.service._find_existing_retrieval_files.assert_called_once()
        self.mock_client.assistants_delete.assert_called_once_with("assistant_id")
        self.mock_client.vector_stores_delete.assert_any_call("vs1_id")
        self.mock_client.vector_stores_delete.assert_any_call("vs2_id")
        self.mock_client.files_delete.assert_any_call("file1_id")
        self.mock_client.files_delete.assert_any_call("file2_id")

    def test_delete_assistant_with_no_existing_assistant_and_files(self):
        """
        Test that delete_assistant does not delete anything when no assistant or files exist.
        """
        self.service._find_existing_assistant = MagicMock(return_value=None)
        self.service._find_existing_retrieval_files = MagicMock(return_value=None)

        self.service.delete_assistant()

        self.service._find_existing_assistant.assert_called_once()
        self.service._find_existing_retrieval_files.assert_called_once()
        self.mock_client.assistants_delete.assert_not_called()
        self.mock_client.files_delete.assert_not_called()

    # pylint: enable=protected-access

```

## continuous-integration.yml

### Summary

This code defines a GitHub Actions workflow named "Continuous Integration" that is triggered on any push to any branch. It consists of a single job called "Tests," which runs on the latest Ubuntu environment. The steps involved include checking out the repository, setting up Python version 3.x, installing dependencies using Hatch, and finally running unit tests defined in the project.

```yml
name: Continuous Integration

on:
  push:
    branches: ["**"]

jobs:
  tests:
    name: "Tests"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.x"
      - name: Install dependencies
        run: |
          python -m pip install hatch
          hatch env create
      - name: Unit tests
        run: |
          hatch run test
```

## openai_api_test.py

### Summary

The provided code is a set of unit tests for an OpenAI API client using Python's `unittest` framework. It includes:

1. **Mocking OpenAI Class**: The `OpenAI` class is mocked to test the `build_openai_client` function, ensuring it creates an instance with a timeout of 90 seconds.

2. **Test Class for OpenAIClient**: A `TestOpenAIClient` class is created, inheriting from `TestCase`. It initializes a mocked OpenAI instance for testing various methods.

3. **Test Methods**: Each test method verifies specific functionalities:

   - `threads_create`, `messages_list`, `messages_create`, etc., ensure that each method in `OpenAIClient` calls the correct API methods with appropriate parameters.
   - Tests for creating, retrieving, deleting, and listing assistants and files.
   - Tests for handling vector store operations (create, retrieve, update, delete).

4. **Error and Logging Handling**: Some tests check for correct logging behavior in case of failures during vector store operations.

Overall, the code validates that the `OpenAIClient` class correctly interacts with the mocked OpenAI API, checking the parameters and response handling in various scenarios.

```py
from unittest import TestCase
from unittest.mock import MagicMock, patch

from .openai_api import OpenAIClient, build_openai_client


@patch("ai_assistant_manager.clients.openai_api.OpenAI")
def test_build_openai_client(mock_openai):
    """
    Test that build_openai_client returns an instance of OpenAI with the correct timeout.
    """
    client = build_openai_client()

    assert client is mock_openai.return_value
    mock_openai.assert_called_once_with(timeout=90)


class TestOpenAIClient(TestCase):
    client: OpenAIClient
    mock_open_ai: MagicMock

    def setUp(self):
        """
        Set up the test case with a mocked OpenAI instance.
        """
        self.mock_open_ai = MagicMock()
        self.client = OpenAIClient(self.mock_open_ai)

    def test_threads_create(self):
        """
        Test that threads_create calls the correct OpenAI API method.
        """
        self.client.threads_create()
        self.mock_open_ai.beta.threads.create.assert_called()

    def test_messages_list(self):
        """
        Test that messages_list calls the correct OpenAI API method with the correct parameters.
        """
        thread_id = "thread_id"
        self.client.messages_list(thread_id)
        self.mock_open_ai.beta.threads.messages.list.assert_called_once_with(thread_id)

    def test_messages_create(self):
        """
        Test that messages_create calls the correct OpenAI API method with the correct parameters.
        """
        thread_id = "thread_id"
        content = "Hello"
        role = "user"
        self.client.messages_create(thread_id, content, role)
        self.mock_open_ai.beta.threads.messages.create.assert_called_once_with(
            thread_id=thread_id, content=content, role=role
        )

    def test_runs_create(self):
        """
        Test that runs_create calls the correct OpenAI API method with the correct parameters.
        """
        thread_id = "thread_id"
        assistant_id = "assistant_id"
        self.client.runs_create(assistant_id, thread_id, False)
        self.mock_open_ai.beta.threads.runs.create_and_poll.assert_called_once_with(
            thread_id=thread_id, assistant_id=assistant_id, tool_choice=None
        )

    def test_runs_create_with_tool_choice(self):
        """
        Test that runs_create calls the correct OpenAI API method with tool choice.
        """
        thread_id = "thread_id"
        assistant_id = "assistant_id"
        self.client.runs_create(assistant_id, thread_id, True)
        self.mock_open_ai.beta.threads.runs.create_and_poll.assert_called_once_with(
            thread_id=thread_id, assistant_id=assistant_id, tool_choice={"type": "file_search"}
        )

    def test_runs_retrieve(self):
        """
        Test that runs_retrieve calls the correct OpenAI API method with the correct parameters.
        """
        run_id = "run_id"
        thread_id = "thread_id"
        self.client.runs_retrieve(run_id, thread_id)
        self.mock_open_ai.beta.threads.runs.retrieve.assert_called_once_with(run_id, thread_id=thread_id)

    def test_assistants_list(self):
        """
        Test that assistants_list calls the correct OpenAI API method.
        """
        self.client.assistants_list()
        self.mock_open_ai.beta.assistants.list.assert_called_once()

    def test_assistants_create(self):
        """
        Test that assistants_create calls the correct OpenAI API method with the correct parameters.
        """
        name = "assistant_name"
        instructions = "instructions"
        tools = [{"tool_name": "tool"}]
        vector_store_ids = ["vector_store_id"]
        self.client.assistants_create(name, instructions, vector_store_ids, tools)
        self.mock_open_ai.beta.assistants.create.assert_called_once_with(
            name=name,
            instructions=instructions,
            model="gpt-4o-2024-08-06",
            tool_resources={"file_search": {"vector_store_ids": vector_store_ids}},
            tools=tools,
        )

    def test_assistants_delete(self):
        """
        Test that assistants_delete calls the correct OpenAI API method with the correct parameters.
        """
        assistant_id = "assistant_id"
        self.client.assistants_delete(assistant_id)
        self.mock_open_ai.beta.assistants.delete.assert_called_once_with(assistant_id)

    def test_files_list(self):
        """
        Test that files_list calls the correct OpenAI API method and returns the expected result.
        """
        files = self.client.files_list()
        self.mock_open_ai.files.list.assert_called_once()
        assert files == self.mock_open_ai.files.list.return_value

    def test_files_get(self):
        """
        Test that files_get calls the correct OpenAI API method with the correct parameters and returns the expected result.
        """
        file_id = "file_id"
        file = self.client.files_get(file_id)
        self.mock_open_ai.files.retrieve.assert_called_once_with(file_id)
        assert file == self.mock_open_ai.files.retrieve.return_value

    def test_files_create(self):
        """
        Test that files_create calls the correct OpenAI API method with the correct parameters.
        """
        file = MagicMock()
        purpose = "assistants"
        self.client.files_create(file, purpose)
        self.mock_open_ai.files.create.assert_called_once_with(file=file, purpose=purpose)

    def test_files_delete(self):
        """
        Test that files_delete calls the correct OpenAI API method with the correct parameters.
        """
        file_id = "file_id"
        self.client.files_delete(file_id)
        self.mock_open_ai.files.delete.assert_called_once_with(file_id)

    def test_vector_stores_list(self):
        """
        Test that vector_stores_list calls the correct OpenAI API method and returns the expected result.
        """
        vector_stores = self.client.vector_stores_list()
        self.mock_open_ai.beta.vector_stores.list.assert_called_once()
        assert vector_stores == self.mock_open_ai.beta.vector_stores.list.return_value

    def test_vector_stores_retrieve(self):
        """
        Test that vector_stores_retrieve calls the correct OpenAI API method with the correct parameters and returns the expected result.
        """
        vector_store_id = "vector_store_id"
        vector_store = self.client.vector_stores_retrieve(vector_store_id)
        self.mock_open_ai.beta.vector_stores.retrieve.assert_called_once_with(vector_store_id)
        assert vector_store == self.mock_open_ai.beta.vector_stores.retrieve.return_value

    @patch("ai_assistant_manager.clients.openai_api.time")
    def test_vector_stores_create(self, mock_time):
        """
        Test that vector_stores_create calls the correct OpenAI API method and handles polling correctly.
        """
        file_ids = ["file_id"]
        name = "vector_store_name"
        self.mock_open_ai.beta.vector_stores.retrieve.side_effect = [
            MagicMock(status="pending", file_counts=MagicMock(failed=0)),
            MagicMock(status="completed", file_counts=MagicMock(failed=0)),
        ]
        vector_store_id = self.client.vector_stores_create(name, file_ids)
        self.mock_open_ai.beta.vector_stores.create.assert_called_once_with(name=name, file_ids=file_ids)
        assert vector_store_id == self.mock_open_ai.beta.vector_stores.create.return_value.id
        assert mock_time.sleep.call_count == 1

    @patch("ai_assistant_manager.clients.openai_api.logger")
    def test_vector_stores_create_with_failed_files(self, mock_logger):
        """
        Test that vector_stores_create logs a warning if there are failed files.
        """
        file_ids = ["file_id"]
        name = "vector_store_name"
        self.mock_open_ai.beta.vector_stores.retrieve.side_effect = [
            MagicMock(status="completed", file_counts=MagicMock(failed=1)),
        ]
        self.client.vector_stores_create(name, file_ids)
        self.mock_open_ai.beta.vector_stores.create.assert_called_once_with(name=name, file_ids=file_ids)
        assert mock_logger.warning.call_count == 1

    @patch("ai_assistant_manager.clients.openai_api.time")
    @patch("ai_assistant_manager.clients.openai_api.logger")
    def test_vector_stores_update(self, mock_logger, mock_time):
        """
        Test that vector_stores_update calls the correct OpenAI API method and handles polling and logging correctly.
        """
        expected_vector_store_id = "vector_store_id"
        file_ids = ["file_id"]
        self.mock_open_ai.beta.vector_stores.retrieve.side_effect = [
            MagicMock(status="pending", file_counts=MagicMock(failed=0)),
            MagicMock(status="completed", file_counts=MagicMock(failed=1)),
        ]
        vector_store_id = self.client.vector_stores_update(expected_vector_store_id, file_ids)
        self.mock_open_ai.beta.vector_stores.files.create.assert_called_once_with(vector_store_id, file_id=file_ids[0])
        assert vector_store_id == expected_vector_store_id
        assert mock_time.sleep.call_count == 1
        assert mock_logger.warning.call_count == 1

    def test_vector_stores_delete(self):
        """
        Test that vector_stores_delete calls the correct OpenAI API method with the correct parameters.
        """
        vector_store_id = "vector_store_id"
        self.client.vector_stores_delete(vector_store_id)
        self.mock_open_ai.beta.vector_stores.delete.assert_called_once_with(vector_store_id)

    def test_vector_stores_file_delete(self):
        """
        Test that vector_stores_file_delete calls the correct OpenAI API methods with the correct parameters.
        """
        vector_store_id = "vector_store_id"
        file_id = "file_id"
        self.client.vector_stores_file_delete(vector_store_id, file_id)
        self.mock_open_ai.beta.vector_stores.files.delete.assert_called_once_with(
            file_id, vector_store_id=vector_store_id
        )
        self.mock_open_ai.files.delete.assert_called_once_with(file_id)

    def test_vector_stores_files(self):
        """
        Test that vector_stores_files calls the correct OpenAI API method with the correct parameters and returns the expected result.
        """
        vector_store_id = "vector_store_id"
        vector_store_files = self.client.vector_stores_files(vector_store_id)
        self.mock_open_ai.beta.vector_stores.files.list.assert_called_once_with(vector_store_id, limit=100)
        assert vector_store_files == self.mock_open_ai.beta.vector_stores.files.list.return_value

```

## sample_prompt.md

### Summary

The code snippet indicates that the system is set to provide assistance, and it includes a placeholder for the current date, represented as `{{CURRENT_DATE}}`.

```md
You are a helpful assistant.

The current date is {{CURRENT_DATE}}.
```

## README.md

### Summary

The "AI Assistant Manager" project provides tools for managing OpenAI assistants, including creating, listing, and deleting them, along with supporting vector storage and retrieval tasks. It uses the Hatch build system for environment management and testing.

### Key Features:

- **Installation**: Install via PyPI using `pip install ai-assistant-manager`.
- **Setup**: Clone the repository, configure environment variables in a `.env` file, and create a virtual environment with dependencies.
- **Environment Variables**: Customize settings such as OpenAI model, assistant name, and directory paths through the `.env` file.
- **Testing**: Run end-to-end tests and unit tests using Hatch.
- **Example Usage**: The provided example demonstrates exporting files, building an OpenAI client, and sending a message to the assistant while logging output.

### Contribution Guidelines:

Contributors can fork the repository, create a branch for changes, run tests, and submit a pull request.

### Code of Conduct:

Contributors are expected to maintain respectful communication and report any inappropriate behavior.

````md
# AI Assistant Manager

This repository provides tools and services to manage OpenAI Assistants, including creating, listing, and deleting assistants, as well as handling vector stores and retrieval files. It includes end-to-end and unit tests, and leverages the Hatch build system for environment management and testing.

## Install through PyPI

```bash
pip install ai-assistant-manager
```
````

For more details, visit the [PyPI project page](https://pypi.org/project/ai-assistant-manager/).

## Setup

1. Clone the repository:

```bash
git clone https://github.com/DEV3L/ai-assistant-manager
cd ai-assistant-manager
```

2. Copy the env.local file to a new file named .env and replace `OPENAI_API_KEY` with your actual OpenAI API key:

```bash
cp env.local .env
```

3. Setup a virtual environment with dependencies and activate it:

```bash
brew install hatch
hatch env create
hatch shell
```

## Environment Variables

The following environment variables can be configured in the `.env` file:

- `OPENAI_MODEL`: The model to use (default: `gpt-4o-2024-08-06`)
- `ASSISTANT_DESCRIPTION`: Description of the assistant (default: `AI Assistant Manager`)
- `ASSISTANT_NAME`: Name of the assistant (default: `AI Assistant Manager`)
- `BIN_DIR`: Directory for binaries (default: `bin`)
- `DATA_DIR`: Directory for data files (default: `data`)
- `DATA_FILE_PREFIX`: Prefix for data files (default: `AI Assistant Manager`)

## Testing

### End to End Test

```bash
hatch run e2e
```

### Unit Tests

```bash
hatch run test
```

### Coverage Gutters:

```bash
Command + Shift + P => Coverage Gutters: Watch
```

## Example

```
from loguru import logger

from ai_assistant_manager.assistants.assistant_service import (
    AssistantService,
)
from ai_assistant_manager.chats.chat import Chat
from ai_assistant_manager.clients.openai_api import OpenAIClient, build_openai_client
from ai_assistant_manager.env_variables import set_env_variables
from ai_assistant_manager.exporters.directory.directory_exporter import DirectoryExporter
from ai_assistant_manager.exporters.files.files_exporter import FilesExporter
from ai_assistant_manager.prompts.prompt import get_prompt


def main():
    DirectoryExporter("directory").export()
    FilesExporter("about.txt").export()

    assistant_name = "AI-Assistant-Manager-Test"
    logger.info(f"Building {assistant_name}")

    client = OpenAIClient(build_openai_client())
    service = AssistantService(client, get_prompt())

    logger.info("Removing existing assistant and category files")
    service.delete_assistant()

    assistant_id = service.get_assistant_id()
    logger.info(f"Assistant ID: {assistant_id}")

    chat = Chat(client, assistant_id)
    chat.start()

    message = "What is the AI Assistant Manager?"
    print(f"\nMessage:\n{message}")

    chat_response = chat.send_user_message(message)
    print(f"\n{service.assistant_name}:\n{chat_response.message}")
    print(f"\nTokens: {chat_response.token_count}")

    // service.delete_assistant()


if __name__ == "__main__":
    try:
        set_env_variables()
        main()
    except Exception as e:
        logger.info(f"Error: {e}")
```

## Contributing

We welcome contributions! To contribute:

1. Fork the repository.
2. Create a new branch for your feature or bugfix.
3. Make your changes.
4. Ensure all tests pass.
5. Submit a pull request with a detailed description of your changes.

## Code of Conduct

We expect all contributors to adhere to our Code of Conduct:

- Be respectful and considerate.
- Avoid discriminatory or offensive language.
- Report any unacceptable behavior to the project maintainers.

By participating in this project, you agree to abide by these guidelines.

````
## openai_api.py

### Summary

The code defines an `OpenAIClient` class to interact with the OpenAI API, encapsulating functionalities to manage threads, messages, assistants, files, and vector stores.

Key components include:

- **OpenAI Client Initialization**: A separate `build_openai_client` function initializes the OpenAI client with a 90-second timeout.
- **Constructor**: Takes an OpenAI instance and a model name.
- **Methods**:
  - Create and retrieve threads and messages.
  - Create, delete, and list assistants.
  - Manage files (create, delete, retrieve, list).
  - Handle vector stores (create, update, delete, and list files).
- **Timers**: Each method is decorated with a timer for performance tracking.

The class uses the OpenAI API's beta features and handles asynchronous operations, ensuring readiness of vector stores after creation or update. The methods utilize logging to indicate progress and potential issues during file uploads.

```py
import time
from io import BufferedReader
from typing import Literal

from loguru import logger
from openai import OpenAI

from ..env_variables import ENV_VARIABLES
from ..timer.timer import timer


def build_openai_client():
    """
    Build and return an OpenAI client with a specified timeout.

    :return: An instance of OpenAI client with a 90-second timeout.
    """
    return OpenAI(timeout=90)


class OpenAIClient:
    """
    A client class to interact with the OpenAI API, providing various methods to manage threads,
    messages, runs, assistants, files, and vector stores.
    """

    def __init__(self, open_ai: OpenAI, *, open_ai_model: str | None = None):
        """
        Initialize the OpenAIClient with an OpenAI instance.

        :param open_ai: An instance of the OpenAI client.
        """
        self.open_ai = open_ai
        self.open_ai_model = open_ai_model if open_ai_model else ENV_VARIABLES.openai_model

    @timer("OpenAIClient.threads_create")
    def threads_create(self):
        """
        Create a new thread using the OpenAI API.

        :return: The created thread object.
        """
        return self.open_ai.beta.threads.create()

    @timer("OpenAIClient.messages_list")
    def messages_list(self, thread_id: str):
        """
        List all messages in a specified thread.

        :param thread_id: The ID of the thread to list messages from.
        :return: A list of messages in the thread.
        """
        return self.open_ai.beta.threads.messages.list(thread_id)

    @timer("OpenAIClient.messages_create")
    def messages_create(self, thread_id: str, content: str, role: Literal["user", "assistant"]):
        """
        Create a new message in a specified thread.

        :param thread_id: The ID of the thread to create a message in.
        :param content: The content of the message.
        :param role: The role of the message sender (either "user" or "assistant").
        :return: The created message object.
        """
        return self.open_ai.beta.threads.messages.create(
            thread_id=thread_id,
            content=content,
            role=role,
        )

    @timer("OpenAIClient.runs_create")
    def runs_create(self, assistant_id: str, thread_id: str, should_force_tool_call: bool):
        """
        Create and poll a new run in a specified thread.

        :param assistant_id: The ID of the assistant to create a run for.
        :param thread_id: The ID of the thread to create a run in.
        :param should_force_tool_call: Whether to force a tool call during the run.
        :return: The created run object.
        """
        return self.open_ai.beta.threads.runs.create_and_poll(
            assistant_id=assistant_id,
            thread_id=thread_id,
            tool_choice={"type": "file_search"} if should_force_tool_call else None,
        )

    @timer("OpenAIClient.runs_retrieve")
    def runs_retrieve(self, run_id: str, thread_id: str):
        """
        Retrieve a specific run in a specified thread.

        :param run_id: The ID of the run to retrieve.
        :param thread_id: The ID of the thread the run belongs to.
        :return: The retrieved run object.
        """
        return self.open_ai.beta.threads.runs.retrieve(run_id, thread_id=thread_id)

    @timer("OpenAIClient.assistants_list")
    def assistants_list(self):
        """
        List all assistants.

        :return: A list of assistants.
        """
        return self.open_ai.beta.assistants.list()

    @timer("OpenAIClient.assistants_create")
    def assistants_create(
        self,
        name: str,
        instructions: str,
        vector_store_ids: list[str],
        tools: list[dict] = None,
    ):
        """
        Create a new assistant with specified parameters.

        :param name: The name of the assistant.
        :param instructions: The instructions for the assistant.
        :param vector_store_ids: A list of vector store IDs associated with the assistant.
        :param tools: A list of tools to be used by the assistant (optional).
        :return: The created assistant object.
        """
        return self.open_ai.beta.assistants.create(
            name=name,
            instructions=instructions,
            model=self.open_ai_model,
            tool_resources={"file_search": {"vector_store_ids": vector_store_ids}},
            tools=tools,
        )

    @timer("OpenAIClient.assistants_delete")
    def assistants_delete(self, assistant_id: str):
        """
        Delete a specified assistant.

        :param assistant_id: The ID of the assistant to delete.
        """
        self.open_ai.beta.assistants.delete(assistant_id)

    @timer("OpenAIClient.files_list")
    def files_list(self):
        """
        List all files.

        :return: A list of files.
        """
        return self.open_ai.files.list()

    @timer("OpenAIClient.files_get")
    def files_get(self, file_id: str):
        """
        Retrieve a specific file.

        :param file_id: The ID of the file to retrieve.
        :return: The retrieved file object.
        """
        return self.open_ai.files.retrieve(file_id)

    @timer("OpenAIClient.files_create")
    def files_create(self, file: BufferedReader, purpose: Literal["assistants", "batch", "fine-tune"]):
        """
        Create a new file with a specified purpose.

        :param file: The file to be uploaded.
        :param purpose: The purpose of the file (e.g., "assistants", "batch", "fine-tune").
        :return: The created file object.
        """
        return self.open_ai.files.create(file=file, purpose=purpose)

    @timer("OpenAIClient.files_delete")
    def files_delete(self, file_id: str):
        """
        Delete a specified file.

        :param file_id: The ID of the file to delete.
        """
        self.open_ai.files.delete(file_id)

    @timer("OpenAIClient.vector_stores_list")
    def vector_stores_list(self):
        """
        List all vector stores.

        :return: A list of vector stores.
        """
        return self.open_ai.beta.vector_stores.list()

    @timer("OpenAIClient.vector_stores_retrieve")
    def vector_stores_retrieve(self, vector_store_id: str):
        """
        Retrieve a specific vector store.

        :param vector_store_id: The ID of the vector store to retrieve.
        :return: The retrieved vector store object.
        """
        return self.open_ai.beta.vector_stores.retrieve(vector_store_id)

    @timer("OpenAIClient.vector_stores_create")
    def vector_stores_create(self, name: str, file_ids: list[str]):
        """
        Create a new vector store with specified parameters.

        :param name: The name of the vector store.
        :param file_ids: A list of file IDs to be included in the vector store.
        :return: The ID of the created vector store.
        """
        created_vector_store = self.open_ai.beta.vector_stores.create(name=name, file_ids=file_ids)
        vector_store_id = created_vector_store.id

        # Poll the vector store until its status is "completed"
        while (vector_store := self.vector_stores_retrieve(vector_store_id)).status != "completed":
            logger.info("Waiting for vector store to be ready")
            time.sleep(5)

        if vector_store.file_counts.failed > 0:
            logger.warning(
                f"Some files ({vector_store.file_counts.failed}) failed when uploaded to vector store ({vector_store_id})"
            )

        return vector_store_id

    @timer("OpenAIClient.vector_stores_update")
    def vector_stores_update(self, vector_store_id: str, file_ids: list[str]):
        """
        Update a vector store by adding new files to it.

        :param vector_store_id: The ID of the vector store to update.
        :param file_ids: A list of file IDs to add to the vector store.
        :return: The ID of the updated vector store.
        """
        # Add each file to the vector store
        [self.open_ai.beta.vector_stores.files.create(vector_store_id, file_id=file_id) for file_id in file_ids]

        # Poll the vector store until its status is "completed"
        while (vector_store := self.vector_stores_retrieve(vector_store_id)).status != "completed":
            logger.info("Waiting for vector store to be ready")
            time.sleep(5)

        if vector_store.file_counts.failed > 0:
            logger.warning(
                f"Some files ({vector_store.file_counts.failed}) failed when uploaded to vector store ({vector_store_id})"
            )
        return vector_store_id

    @timer("OpenAIClient.vector_stores_delete")
    def vector_stores_delete(self, vector_store_id: str):
        """
        Delete a specified vector store.

        :param vector_store_id: The ID of the vector store to delete.
        """
        self.open_ai.beta.vector_stores.delete(vector_store_id)

    @timer("OpenAIClient.vector_stores_file_delete")
    def vector_stores_file_delete(self, vector_store_id: str, file_id: str):
        """
        Delete a specific file from a vector store and also delete the file itself.

        :param vector_store_id: The ID of the vector store.
        :param file_id: The ID of the file to delete.
        """
        self.open_ai.beta.vector_stores.files.delete(file_id, vector_store_id=vector_store_id)
        self.files_delete(file_id)

    @timer("OpenAIClient.vector_stores_files")
    def vector_stores_files(self, vector_store_id: str):
        """
        List all files in a specified vector store.

        :param vector_store_id: The ID of the vector store to list files from.
        :return: A list of files in the vector store.
        """
        return self.open_ai.beta.vector_stores.files.list(vector_store_id, limit=100)

````

## chat.py

### Summary

The provided code defines a `Chat` class that facilitates interactions with an AI assistant using an OpenAI client. The class manages chat threads, allowing users to send messages, run threads, and retrieve the last response.

Key functionalities include:

- **Initialization**: Takes an OpenAI client, assistant ID, and an optional thread ID.
- **Starting a Chat**: Creates a new chat thread if none exists.
- **Sending User Messages**: Sends a message to the thread and processes the assistant's response.
- **Running Threads**: Executes the chat thread and waits for its completion, checking for errors like failure or timeout.
- **Retrieving Messages**: Fetches all messages from the thread and extracts the last one.
- **Tool Call Handling**: Supports messages prefixed with a specific string to trigger special behavior.

The code also includes logging for various operations, error handling, and a timed waiting mechanism for responses.

```py
import time

from loguru import logger

from ..clients.openai_api import OpenAIClient
from ..timer.timer import timer
from .chat_response import ChatResponse

TOOL_CALL_PREFIX = "tc!"


class Chat:
    """
    A class to manage chat interactions with an AI assistant. This class handles the creation of threads,
    sending messages, running threads, and retrieving messages.
    """

    def __init__(
        self,
        client: OpenAIClient,
        assistant_id: str,
        *,
        thread_id: str | None = None,
    ):
        """
        Initialize the Chat instance with a client, assistant ID, and optional thread ID.

        :param client: The OpenAIClient instance to interact with the OpenAI API.
        :param assistant_id: The ID of the assistant to interact with.
        :param thread_id: The ID of the thread to use (optional).
        """
        self.client = client
        self.assistant_id = assistant_id
        self.thread_id = thread_id

    def start(self):
        """
        Start a new chat thread if one does not already exist.

        This method ensures that a thread ID is available for the chat session.
        """
        logger.info("Starting Chat")
        # Create a new thread if thread_id is not already set
        self.thread_id = self.thread_id or self.create_thread()
        logger.info(f"Thread ID: {self.thread_id}")

    def create_thread(self):
        return self.client.threads_create().id

    def send_user_message(self, message: str) -> ChatResponse:
        """
        Send a user message to the chat thread and run the thread.

        :param message: The message content to send.
        :return: The last message content from the thread.
        """
        self.client.messages_create(
            self.thread_id,
            self.remove_tool_call_from_message(message),
            "user",
        )

        # Run the thread, potentially forcing a tool call
        tokens = self.run_thread(self.should_force_tool_call(message))
        return ChatResponse(message=self.last_message(), token_count=tokens)

    @timer("Run Thread")
    def run_thread(self, should_force_tool_call: bool) -> int:
        """
        Run the thread, potentially forcing a tool call.

        :param should_force_tool_call: Whether to force a tool call during the run.
        :return: The total number of tokens used in the run.
        """
        run = self.client.runs_create(self.assistant_id, self.thread_id, should_force_tool_call)
        return self._wait_for_run_to_complete(run.id)

    def _wait_for_run_to_complete(self, run_id: str, *, step: float = 0.25, timeout_in_seconds: int = 120) -> int:
        """
        Wait for a run to complete, polling at regular intervals.

        :param run_id: The ID of the run to wait for.
        :param step: The polling interval in seconds.
        :param timeout_in_seconds: The maximum time to wait in seconds.
        :raises RuntimeError: If the run fails or times out.
        :return: The total number of tokens used in the run.
        """
        timeout = timeout_in_seconds / step

        while timeout > 0:
            run = self.client.runs_retrieve(run_id, self.thread_id)

            if run.status in ["completed"]:
                return run.usage.total_tokens
            # requires_action will need to be handled by user
            if run.status in ["failed", "expired", "cancelled", "requires_action"]:
                raise RuntimeError(f"Run failed with status: {run.status}")

            timeout -= 1
            time.sleep(step)

        raise RuntimeError(f"Run timed out after {timeout_in_seconds} seconds")

    def last_message(self) -> str:
        """
        Retrieve the last message content from the thread.

        :return: The content of the last message.
        :raises RuntimeError: If no text content is found in the messages.
        """
        message_content = self._get_messages()[0].content[0]
        if hasattr(message_content, "text"):
            return message_content.text.value

        raise RuntimeError("No text content found in the messages")

    def _get_messages(self):
        """
        Retrieve all messages from the thread.

        :return: A list of messages in the thread.
        """
        return self.client.messages_list(self.thread_id).data

    def remove_tool_call_from_message(self, message: str) -> str:
        """
        Remove the tool call prefix from the message if it exists.

        :param message: The message content to process.
        :return: The message content without the tool call prefix.
        """
        return message.replace(TOOL_CALL_PREFIX, "", 1) if self.should_force_tool_call(message) else message

    def should_force_tool_call(self, message: str) -> bool:
        """
        Determine if the message should force a tool call.

        :param message: The message content to check.
        :return: True if the message starts with the tool call prefix, False otherwise.
        """
        return message.startswith(TOOL_CALL_PREFIX)

```

## chat_test.py

### Summary

The provided code is a unit test suite for a `Chat` class implemented using the `unittest` framework in Python, along with mocking functionality from `unittest.mock`. Here's a summary of its functionality:

1. **Setup**: In `setUp`, a mock client and a `Chat` instance are initialized for use in tests.

2. **Test Cases**:
   - **start and thread management**: Tests verify that starting a chat can set or retain the thread ID properly.
   - **Create Thread**: Ensures a thread can be correctly created and retrieves its ID.
   - **Send Message**: Tests sending a user message and checking its response, including that the appropriate methods are called.
   - **Running Threads**: Tests the behavior of running a thread, completing runs, waiting for completion, and handling successful, failed, and timeout scenarios.
   - **Retrieve Last Message**: Tests that the last message can be retrieved correctly, handling various message formats and potential errors.
   - **Tool Call Management**: Tests for removing tool calls from messages and determining if a message should trigger a tool call.

Overall, the suite covers various aspects of the `Chat` class functionality, focusing on thread management, message handling, and error management within a chat system.

```py
from unittest import TestCase
from unittest.mock import MagicMock, patch

import pytest
from openai.types.beta.threads.text import Text
from openai.types.beta.threads.text_content_block import TextContentBlock

from .chat import Chat
from .chat_response import ChatResponse


class TestChat(TestCase):
    chat: Chat
    assistant_id = "assistant_id"

    mock_client: MagicMock

    def setUp(self):
        """
        Set up the test case with a mocked client and a Chat instance.
        """
        self.mock_client = MagicMock()
        self.chat = Chat(self.mock_client, self.assistant_id)

    def test_chat_start_sets_thread_id(self):
        """
        Test that starting a chat sets the thread ID correctly.
        """
        self.mock_client.threads_create.return_value.id = "thread_id"

        self.chat.start()

        assert self.chat.thread_id == "thread_id"

    def test_chat_create_thread(self):
        self.mock_client.threads_create.return_value.id = "thread_id"

        thread_id = self.chat.create_thread()

        assert thread_id == "thread_id"

    def test_chat_start_with_thread(self):
        """
        Test that starting a chat with an existing thread ID does not change the thread ID.
        """
        self.chat.thread_id = "my_thread_id"

        self.chat.start()

        assert self.chat.thread_id == "my_thread_id"

    def test_send_user_message(self):
        """
        Test that sending a user message works correctly and triggers the appropriate methods.
        """
        self.mock_client.messages_create.return_value = None
        self.mock_client.messages_list.return_value.data = [{"content": "Hello"}]
        self.chat.thread_id = "thread_id"
        self.chat.run_thread = MagicMock(return_value=10)
        self.chat.last_message = MagicMock(return_value="Hello")

        result = self.chat.send_user_message("Test message")

        assert result == ChatResponse(message="Hello", token_count=10)
        self.mock_client.messages_create.assert_called_once_with("thread_id", "Test message", "user")
        self.chat.run_thread.assert_called_once()
        self.chat.last_message.assert_called_once()

    def test_chat_run_thread(self):
        """
        Test that running a thread creates a run and waits for it to complete.
        """
        self.mock_client.runs_create.return_value.id = "run_id"
        self.chat.thread_id = "thread_id"

        with patch.object(self.chat, "_wait_for_run_to_complete") as mock_wait_for_run_to_complete:
            self.chat.run_thread(False)

        mock_wait_for_run_to_complete.assert_called_once_with("run_id")

    def test_wait_for_run_to_complete_success(self):
        """
        Test that waiting for a run to complete works correctly when the run is successful.
        """
        self.mock_client.runs_retrieve.return_value.status = "completed"

        with patch("time.sleep", return_value=None):
            # pylint: disable=protected-access
            self.chat._wait_for_run_to_complete("run_id")

        self.mock_client.runs_retrieve.assert_called_with(
            "run_id",
            self.chat.thread_id,
        )

    def test_wait_for_run_to_complete_failure(self):
        """
        Test that waiting for a run to complete raises an error when the run fails.
        """
        self.mock_client.runs_retrieve.return_value.status = "failed"

        with patch("time.sleep", return_value=None):
            with pytest.raises(RuntimeError, match="Run failed with status: failed"):
                # pylint: disable=protected-access
                self.chat._wait_for_run_to_complete("run_id")

        self.mock_client.runs_retrieve.assert_called_with(
            "run_id",
            self.chat.thread_id,
        )

    def test_wait_for_run_to_complete_timeout(self):
        """
        Test that waiting for a run to complete raises an error when the run times out.
        """
        self.mock_client.runs_retrieve.return_value.status = "running"

        with patch("time.sleep", return_value=None):
            with pytest.raises(RuntimeError, match="Run timed out after 1 seconds"):
                # pylint: disable=protected-access
                self.chat._wait_for_run_to_complete("run_id", timeout_in_seconds=1)

        self.mock_client.runs_retrieve.assert_called_with(
            "run_id",
            self.chat.thread_id,
        )

    def test_last_message(self):
        """
        Test that retrieving the last message works correctly.
        """
        self.mock_client.messages_list.return_value.data = [
            MagicMock(content=[MagicMock(text=MagicMock(value="Hello"))])
        ]
        self.chat.thread_id = "thread_id"

        result = self.chat.last_message()

        assert result == "Hello"
        self.mock_client.messages_list.assert_called_once_with("thread_id")

    def test_last_message_with_text_content(self):
        """
        Test that retrieving the last message with text content works correctly.
        """
        self.chat._get_messages = MagicMock(
            return_value=[
                MagicMock(content=[TextContentBlock(text=Text(annotations=[], value="Hello, world!"), type="text")])
            ]
        )
        assert self.chat.last_message() == "Hello, world!"

    def test_last_message_with_no_text_content(self):
        """
        Test that retrieving the last message raises an error when there is no text content.
        """
        not_text = MagicMock()
        delattr(not_text, "text")
        self.chat._get_messages = MagicMock(return_value=[MagicMock(content=[not_text])])
        with pytest.raises(RuntimeError, match="No text content found in the messages"):
            self.chat.last_message()

    def test_remove_tool_call_from_message(self):
        """
        Test that removing a tool call from a message works correctly.
        """
        assert self.chat.remove_tool_call_from_message("tc! call") == " call"
        assert self.chat.remove_tool_call_from_message(" tc! call") == " tc! call"

    def test_should_force_tool_call(self):
        """
        Test that checking if a message should force a tool call works correctly.
        """
        assert self.chat.should_force_tool_call("tc!")
        assert not self.chat.should_force_tool_call(" tc!")

```

## content_data.py

### Summary

This code defines a data class named `ContentData` that requires keyword-only arguments for its initialization. It has four attributes: `id`, `title`, `body`, and `date`, all of which are of type `str`. The `@dataclass` decorator automatically generates special methods like `__init__`, `__repr__`, and `__eq__` for the class.

```py
from dataclasses import dataclass


@dataclass(kw_only=True)
class ContentData:
    id: str
    title: str
    body: str
    date: str

```

## env_variables.py

### Summary

This code defines a data class `EnvVariables` to store various environment variables related to an AI assistant. It includes a function `set_env_variables` that loads values from a `.env` file into a global instance of `EnvVariables`, with a fallback to default values if the variables are not set. The global instance is initialized with values from the environment or defaults when the script runs.

```py
import os
from dataclasses import dataclass

from dotenv import load_dotenv


@dataclass
class EnvVariables:
    """
    Data class to store environment variables.
    """

    assistant_description: str
    assistant_name: str
    bin_dir: str
    data_dir: str
    data_file_prefix: str
    openai_model: str


def set_env_variables(env_file_path: str | None = None):
    """
    Load environment variables from a .env file and set them in the global ENV_VARIABLES instance.

    Args:
        env_file_path (str | None): Path to the .env file. If None, defaults to the .env file in the current directory.
    """
    global ENV_VARIABLES

    # Load environment variables from the specified .env file, overriding existing variables
    load_dotenv(env_file_path, override=True)

    # Set the environment variables in the global ENV_VARIABLES instance
    ENV_VARIABLES.assistant_description = os.getenv("ASSISTANT_DESCRIPTION", "AI Assistant Manager")
    ENV_VARIABLES.assistant_name = os.getenv("ASSISTANT_NAME", "AI Assistant Manager")
    ENV_VARIABLES.bin_dir = os.getenv("BIN_DIR", "bin")
    ENV_VARIABLES.data_dir = os.getenv("DATA_DIR", "data")
    ENV_VARIABLES.data_file_prefix = os.getenv("DATA_FILE_PREFIX", "AI Assistant Manager")
    ENV_VARIABLES.openai_model = os.getenv("OPENAI_MODEL", "gpt-4o-2024-08-06")


# Initialize the global ENV_VARIABLES instance with default values or values from the environment
ENV_VARIABLES = EnvVariables(
    assistant_description=os.getenv("ASSISTANT_DESCRIPTION", "AI Assistant Manager"),
    assistant_name=os.getenv("ASSISTANT_NAME", "AI Assistant Manager"),
    bin_dir=os.getenv("BIN_DIR", "bin"),
    data_dir=os.getenv("DATA_DIR", "data"),
    data_file_prefix=os.getenv("DATA_FILE_PREFIX", "AI Assistant Manager"),
    openai_model=os.getenv("OPENAI_MODEL", "gpt-4o-2024-08-06"),
)

```

## directory_exporter_test.py

### Summary

The provided code is a set of unit tests for the `DirectoryExporter` class in the `ai_assistant_manager` module, using `pytest` and `unittest.mock` for mocking dependencies. The tests check the following functionalities:

1. **Fixture Creation**: A fixture named `exporter` creates an instance of `DirectoryExporter` for use in tests.

2. **Export Functionality**:

   - **When Data Exists**: It tests that no directory is created if data already exists.
   - **When Data Does Not Exist**: It tests that a directory is created and data is written when no data exists.

3. **Data Writing**:

   - Tests if the `write_data` method correctly writes JSON data to a file.

4. **Data Loading**:

   - Tests if the `load` method retrieves data from files in the specified directory.
   - Tests the `file_load` method to ensure it correctly loads data from a single file.

5. **Path Retrieval**:
   - Tests methods to verify that they return the correct directory and file paths based on environment variables.

Overall, the tests ensure that the `DirectoryExporter` behaves correctly in various scenarios related to data exportation and file operations.

```py
from unittest.mock import Mock, mock_open, patch

import pytest

from ai_assistant_manager.env_variables import ENV_VARIABLES

from ..content_data import ContentData
from .directory_exporter import DirectoryExporter

example_directory = "directory"


@pytest.fixture(name="exporter")
def build_exporter() -> DirectoryExporter:
    """
    Fixture to create a DirectoryExporter instance for testing.
    """
    return DirectoryExporter(example_directory)


@patch("ai_assistant_manager.exporters.directory.directory_exporter.create_dir")
@patch("ai_assistant_manager.exporters.directory.directory_exporter.does_data_exist")
def test_export_data_exists(mock_does_data_exist: Mock, mock_create_dir: Mock, exporter: DirectoryExporter):
    """
    Test that export does not create directory if data already exists.
    """
    mock_does_data_exist.return_value = True

    exporter.export()

    mock_create_dir.assert_not_called()


@patch("ai_assistant_manager.exporters.directory.directory_exporter.create_dir")
@patch("ai_assistant_manager.exporters.directory.directory_exporter.does_data_exist")
def test_export_data_does_not_exist(mock_does_data_exist: Mock, mock_create_dir: Mock, exporter: DirectoryExporter):
    """
    Test that export creates directory and writes data if data does not exist.
    """
    mock_does_data_exist.return_value = False

    exporter.write_data = Mock()

    exporter.export()

    mock_create_dir.assert_called_once()
    exporter.write_data.assert_called_once()


@patch("builtins.open", new_callable=mock_open)
@patch("json.dumps")
def test_write_data(mock_json_dumps: Mock, mock_open_file: Mock, exporter: DirectoryExporter):
    """
    Test that write_data correctly writes JSON data to a file.
    """
    exporter.load = Mock(return_value=[])
    mock_json_dumps.return_value = "{}"

    exporter.write_data()

    exporter.load.assert_called_once()
    mock_open_file.assert_called_once_with(exporter.get_file_path(), "w", encoding="utf-8")
    mock_open_file().write.assert_called_once_with(mock_json_dumps.return_value)


@patch("os.listdir")
def test_load(mock_listdir: Mock, exporter: DirectoryExporter):
    """
    Test that load correctly loads data from files in the directory.
    """
    exporter.file_load = Mock(return_value=ContentData(id="1", title="Test", body="Test body", date="2022-01-01"))
    mock_listdir.return_value = ["01 We Call It Saw Time.txt"]

    result = exporter.load()

    assert len(result) == 1
    assert all(isinstance(item, ContentData) for item in result)


def test_file_load(exporter: DirectoryExporter):
    """
    Test that file_load correctly loads data from a single file.
    """
    exporter.get_data_dir_path = Mock(return_value="data/directory")

    filename = "001 Test File.md"
    blog_data = exporter.file_load(filename)

    assert blog_data.id == "001"
    assert blog_data.title == "Test File"
    assert isinstance(blog_data.body, str)
    assert blog_data.date == "2024-08-12T00:00:00"


def test_get_dir_path(exporter: DirectoryExporter):
    """
    Test that get_dir_path returns the correct directory path.
    """
    result = exporter.get_dir_path()

    assert result == f"{ENV_VARIABLES.bin_dir}/{example_directory}"


def test_get_file_path(exporter: DirectoryExporter):
    """
    Test that get_file_path returns the correct file path.
    """
    result = exporter.get_file_path()

    assert (
        result
        == f"{ENV_VARIABLES.bin_dir}/{example_directory}/{ENV_VARIABLES.data_file_prefix} - {example_directory}.json"
    )


def test_get_data_dir_path(exporter: DirectoryExporter):
    """
    Test that get_data_dir_path returns the correct data directory path.
    """
    result = exporter.get_data_dir_path()

    assert result == f"{ENV_VARIABLES.data_dir}/{example_directory}"

```

## chat_response.py

### Summary

This code defines a data class called `ChatResponse`, which represents a chat response with two attributes: `message` (a string containing the chat content) and `token_count` (an integer indicating the total number of tokens in the message).

```py
from dataclasses import dataclass


@dataclass
class ChatResponse:
    """
    Represents a response in a chat.

    Attributes:
        message (str): The message content of the chat response.
        token_count (int): The total token count in the chat response.
    """

    message: str
    token_count: int

```

## env_variables_test.py

### Summary

The code defines a test function `test_reset_env_variables` that verifies the functionality of the `set_env_variables` function. It uses the pytest framework to create a temporary `.env` file containing test environment variables. The `set_env_variables` function is called to load these variables, and assertions are made to ensure that the environment variables in the `ENV_VARIABLES` instance are set correctly based on the contents of the `.env` file.

```py
from .env_variables import ENV_VARIABLES, set_env_variables


def test_reset_env_variables(tmp_path):
    """
    Test the set_env_variables function to ensure it correctly sets environment variables
    from a .env file.

    Args:
        tmp_path: pytest fixture that provides a temporary directory unique to the test invocation.
    """
    # Create a temporary .env file with test environment variables
    env_file = tmp_path / ".env"
    env_file.write_text(
        "OPENAI_MODEL=test_model\n"
        "ASSISTANT_DESCRIPTION=test_description\n"
        "ASSISTANT_NAME=test_name\n"
        "BIN_DIR=test_bin\n"
        "DATA_DIR=test_data\n"
        "DATA_FILE_PREFIX=test_prefix\n"
    )

    # Call the function to set environment variables from the .env file
    set_env_variables(str(env_file))

    # Assert the environment variables are set correctly in the ENV_VARIABLES instance
    assert ENV_VARIABLES.assistant_description == "test_description"
    assert ENV_VARIABLES.assistant_name == "test_name"
    assert ENV_VARIABLES.bin_dir == "test_bin"
    assert ENV_VARIABLES.data_dir == "test_data"
    assert ENV_VARIABLES.data_file_prefix == "test_prefix"
    assert ENV_VARIABLES.openai_model == "test_model"

```

## 001 Test File.md

### Summary

This code is a simple text file labeled "Test File." It contains a date (8/12/24) and a line indicating "Some test data."

```md
8/12/24

# Test File

Some test data
```

## assistant_service.py

### Summary

The provided code defines an `AssistantService` class that manages AI assistants and their related resources, including vector stores and retrieval files. It interacts with an `OpenAIClient` to create, find, and delete assistants and associated data.

### Key Components:

- **Initialization (`__init__`)**: Sets up the service with a specified client, prompt, assistant name, data file prefix, and tools.
- **Getting Assistant ID**: Uses `_find_existing_assistant` to search for an existing assistant or `_create_assistant` to create a new one if none is found.
- **Vector Stores**: Manages vector stores through methods to find existing ones or create new ones, including validation of their status.
- **File Management**: Handles retrieval files by finding existing ones or creating new ones from files in a specified directory.
- **Deletion**: Has a method to delete the assistant and all related resources, ensuring complete cleanup.

Overall, this class encapsulates functionality for managing AI assistants and their operational resources effectively while providing logging for key actions.

```py
import os

from loguru import logger

from ..clients.openai_api import OpenAIClient
from ..env_variables import ENV_VARIABLES

RETRIEVAL_TOOLS = [
    {"type": "file_search"},
]


class AssistantService:
    """
    Service class to manage AI assistants and their associated vector stores and files.
    This class interacts with the OpenAIClient to perform operations such as creating,
    finding, and deleting assistants and their related resources.
    """

    def __init__(
        self,
        client: OpenAIClient,
        prompt: str,
        *,
        assistant_name: str | None = None,
        data_file_prefix: str | None = None,
        tools: list[dict] = RETRIEVAL_TOOLS,
    ):
        """
        Initialize the AssistantService with a client, prompt, assistant name, and data file prefix.

        :param client: The OpenAIClient instance to interact with the OpenAI API.
        :param prompt: The prompt to be used for the assistant.
        :param assistant_name: The name of the assistant (default is from environment variables).
        :param data_file_prefix: The prefix for data files (default is from environment variables).
        :param tools: The tools to be used by the assistant.
        """

        self.client = client
        self.prompt = prompt
        self.assistant_name = assistant_name if assistant_name else ENV_VARIABLES.assistant_name
        self.data_file_prefix = data_file_prefix if data_file_prefix else ENV_VARIABLES.data_file_prefix
        self.tools = tools

    def get_assistant_id(self):
        """
        Get the assistant ID, either by finding an existing one or creating a new one.

        :return: The ID of the assistant.
        """
        return self._find_existing_assistant() or self._create_assistant()

    def _find_existing_assistant(self):
        """
        Retrieve the list of assistants and find one that matches the assistant name.

        :return: The ID of the existing assistant or None if not found.
        """
        assistants = self.client.assistants_list()
        return next(
            (assistant.id for assistant in assistants if assistant.name == self.assistant_name),
            None,
        )

    def _create_assistant(self):
        """
        Create a new assistant using the client if no existing assistant is found.

        :return: The ID of the newly created assistant.
        """
        logger.info(f"Creating new assistant {self.assistant_name}")
        return self.client.assistants_create(
            self.assistant_name, self.prompt, self.get_vector_store_ids(), tools=self.tools
        ).id

    def get_vector_store_ids(self):
        """
        Get the vector store IDs, either by finding existing ones or creating new ones.

        :return: A list of vector store IDs.
        """
        return self._find_existing_vector_stores() or self.create_vector_stores()

    def _find_existing_vector_stores(self):
        """
        Retrieve the list of vector stores and find those that match the data file prefix.

        :return: A list of existing vector store IDs.
        """
        vector_stores = self.client.vector_stores_list()
        return [
            vector_store.id
            for vector_store in vector_stores
            if vector_store.name and vector_store.name.startswith(self.data_file_prefix)
        ]

    def create_vector_stores(self):
        """
        Create new vector stores if no existing vector stores are found.

        :return: A list containing the ID of the newly created vector store.
        """
        logger.info("Creating new vector stores")
        retrieval_file_ids = self.get_retrieval_file_ids()
        return [
            self._validate_vector_stores(
                self.client.vector_stores_create(f"{self.data_file_prefix} vector store", retrieval_file_ids)
            )
        ]

    def _validate_vector_stores(self, vector_store_id: str):
        """
        Validate the vector store by checking the status of its files and recreating any failed files.

        :param vector_store_id: The ID of the vector store to validate.
        :return: The validated vector store ID.
        """
        try:
            vector_store_files = self.client.vector_stores_files(vector_store_id)
            failed_files = [file.id for file in vector_store_files if file.status == "failed"]

            if not failed_files:
                return vector_store_id

            # Retrieve details of failed files
            failed_retrieval_files = [self.client.files_get(file) for file in failed_files if file]
            failed_retrieval_file_names = [self._get_file_name(file.filename) for file in failed_retrieval_files]
            failed_file_paths = [
                file_path
                for file_path in self._get_file_paths()
                if self._get_file_name(file_path) in failed_retrieval_file_names
            ]

            # Delete failed files from vector store
            [self.client.vector_stores_file_delete(vector_store_id, file_id) for file_id in failed_files]

            # Recreate failed files
            recreated_files = self._create_files(failed_file_paths)
            self.client.vector_stores_update(vector_store_id, recreated_files)

            # Recursively validate the vector store again
            return self._validate_vector_stores(vector_store_id)
        except Exception as e:
            logger.error(f"Error validating vector store {vector_store_id}: {e}")
            return self._validate_vector_stores(vector_store_id)

    def _get_file_name(self, file_path: str) -> str:
        """
        Extract the file name from the file path.

        :param file_path: The path of the file.
        :return: The name of the file.
        """
        return os.path.basename(file_path)

    def get_retrieval_file_ids(self):
        """
        Get the retrieval file IDs, either by finding existing ones or creating new ones.

        :return: A list of retrieval file IDs.
        """
        return self._find_existing_retrieval_files() or self.create_retrieval_files()

    def _find_existing_retrieval_files(self):
        """
        Retrieve the list of files and find those that match the data file prefix.

        :return: A list of existing retrieval file IDs.
        """
        files = self.client.files_list()
        return [file.id for file in files if file.filename.startswith(self.data_file_prefix)]

    def create_retrieval_files(self):
        """
        Create new retrieval files if no existing retrieval files are found.

        :return: A list of newly created retrieval file IDs.
        """
        logger.info("Creating new retrieval files")
        file_paths = self._get_file_paths()
        return self._create_files(file_paths)

    def _get_file_paths(self):
        """
        Get the paths of all files in the "bin" directory, excluding ".DS_Store" files.

        :return: A list of file paths.
        """
        return [
            os.path.join(root, file)
            for (root, _, files) in os.walk("bin")
            for file in files
            if not file.endswith(".DS_Store")
        ]

    def _create_files(self, file_paths: list[str]):
        """
        Create files using the client for each file path provided.

        :param file_paths: A list of file paths to create files from.
        :return: A list of newly created file IDs.
        """
        return [self._create_file(file_path) for file_path in file_paths]

    def _create_file(self, file_path: str):
        """
        Create a single file using the client.

        :param file_path: The path of the file to create.
        :return: The ID of the newly created file.
        """
        with open(file_path, "rb") as file:
            return self.client.files_create(file, "assistants").id

    def delete_assistant(self):
        """
        Remove the assistant and its associated vector stores and retrieval files.

        This method ensures that all resources related to the assistant are cleaned up.
        """
        logger.info(f"Removing existing {self.assistant_name} and retrieval files")

        if assistant_id := self._find_existing_assistant():
            self.client.assistants_delete(assistant_id)
        if vector_store_ids := self._find_existing_vector_stores():
            for vector_store_id in vector_store_ids:
                self.client.vector_stores_delete(vector_store_id)
        if file_ids := self._find_existing_retrieval_files():
            for file_id in file_ids:
                self.client.files_delete(file_id)

```

## prompt.py

### Summary

This code defines a function `get_prompt` that reads a prompt file from a specified path (defaulting to `SAMPLE_PROMPT_PATH`). It replaces a placeholder `{{CURRENT_DATE}}` in the prompt with the current date in ISO format (YYYY-MM-DD) and returns the modified prompt text. The file is read using UTF-8 encoding.

```py
from datetime import datetime

from ai_assistant_manager.encoding import UTF_8

SAMPLE_PROMPT_PATH = "ai_assistant_manager/prompts/sample_prompt.md"

CURRENT_DATE_VARIABLE = "{{CURRENT_DATE}}"


def get_prompt(*, prompt_path: str = SAMPLE_PROMPT_PATH):
    with open(prompt_path, "r", encoding=UTF_8) as prompt:
        current_date = datetime.today().date().isoformat()
        return prompt.read().replace(CURRENT_DATE_VARIABLE, current_date)

```

## ruff_defaults.toml

### Summary

This code appears to be a configuration file (likely for a Python project) defining style and linting settings. Key points include:

- The maximum line length is set to 120 characters.
- Documentation strings should adhere to a line length of 80 characters.
- Relative imports are banned by the Flake8 tidy imports linter.
- The `isort` linter knows that `src` is a first-party package.
- Flake8 pytest style settings disable parentheses for fixtures and marks.

```toml
line-length = 120

[format]
docstring-code-format = true
docstring-code-line-length = 80

[lint.flake8-tidy-imports]
ban-relative-imports = "all"

[lint.isort]
known-first-party = ["src"]

[lint.flake8-pytest-style]
fixture-parentheses = false
mark-parentheses = false
```

## run_end_to_end.py

### Summary

The code is a Python script that initializes an AI assistant using the OpenAI API. It performs the following steps:

1. **Imports Necessary Modules**: It imports various components needed for functionality, including logging, environment variable management, client interaction with OpenAI, and exporting features.
2. **Main Function**:
   - Exports data from a specified directory and file (`about.txt`).
   - Initializes the assistant service with a unique name.
   - Logs the assistant’s building process.
   - Creates an OpenAI client and an assistant service.
   - Deletes any existing assistant and retrieves a new assistant ID.
   - Starts a chat session with the assistant.
   - Sends a predefined message and prints the response from the assistant along with the token count.
   - Cleans up by deleting the assistant.
3. **Execution Block**: Sets environment variables and calls the main function, handling any exceptions by logging errors.

Overall, it serves as a setup and interaction script for a test AI assistant using OpenAI's API.

```py
from loguru import logger

from ai_assistant_manager.assistants.assistant_service import (
    AssistantService,
)
from ai_assistant_manager.chats.chat import Chat
from ai_assistant_manager.clients.openai_api import OpenAIClient, build_openai_client
from ai_assistant_manager.env_variables import set_env_variables
from ai_assistant_manager.exporters.directory.directory_exporter import DirectoryExporter
from ai_assistant_manager.exporters.files.files_exporter import FilesExporter
from ai_assistant_manager.prompts.prompt import get_prompt


def main():
    DirectoryExporter("directory").export()
    FilesExporter("about.txt").export()

    assistant_name = "AI-Assistant-Manager-Test"
    logger.info(f"Building {assistant_name}")

    client = OpenAIClient(build_openai_client())
    service = AssistantService(client, get_prompt())

    logger.info("Removing existing assistant and category files")
    service.delete_assistant()

    assistant_id = service.get_assistant_id()
    logger.info(f"Assistant ID: {assistant_id}")

    chat = Chat(client, assistant_id)
    chat.start()

    message = "What is the AI Assistant Manager?"
    print(f"\nMessage:\n{message}")

    chat_response = chat.send_user_message(message)
    print(f"\n{service.assistant_name}:\n{chat_response.message}")
    print(f"\nTokens: {chat_response.token_count}")

    service.delete_assistant()


if __name__ == "__main__":
    try:
        set_env_variables()
        main()
    except Exception as e:
        logger.info(f"Error: {e}")

```

## files_exporter.py

### Summary

The `FilesExporter` class is designed to export files to a specified directory, ensuring that existing files are not overwritten. It accepts parameters for file name, target directory, and optional directories for binaries and data files. The class includes methods to check if data already exists, create necessary directories, write the file, and retrieve the file's directory and full path. Logging is integrated to provide information on the export process, including successful data writing and skipping exports if the file already exists.

```py
import os
import shutil

from loguru import logger

from ai_assistant_manager.env_variables import ENV_VARIABLES

from ..exporter import (
    create_dir,
    does_data_exist,
)


class FilesExporter:
    """
    A class to handle exporting files to a specified directory.

    This class ensures that files are only exported if they do not already exist,
    and it manages the creation of necessary directories.
    """

    def __init__(
        self,
        file_name: str,
        *,
        directory: str = "files",
        bin_dir: str | None = None,
        data_dir: str | None = None,
        data_file_prefix: str | None = None,
    ) -> None:
        """
        Initialize the FilesExporter with file and directory information.

        :param file_name: The name of the file to export.
        :param directory: The target directory for the export (default is "files").
        :param bin_dir: The base directory for binaries (default is from environment variables).
        :param data_dir: The base directory for data files (default is from environment variables).
        :param data_file_prefix: The prefix for data files (default is from environment variables).
        """

        self.file_name = file_name
        self.directory = directory
        self.bin_dir = bin_dir if bin_dir else ENV_VARIABLES.bin_dir
        self.data_dir = data_dir if data_dir else ENV_VARIABLES.data_dir
        self.data_file_prefix = data_file_prefix if data_file_prefix else ENV_VARIABLES.data_file_prefix

    def export(self):
        """
        Export the file to the target directory if it does not already exist.

        This method checks for the existence of the file and skips the export if the file is already present.
        It also ensures that the necessary directory structure is created before writing the data.
        """
        if does_data_exist(self.get_file_path()):
            logger.info(f"{self._get_file_name_without_extension()} data exists. Skipping export.")
            return

        logger.info(f"Exporting {self._get_file_name_without_extension()} data")
        create_dir(self.get_dir_path(), self.get_file_path())
        self.write_data()

    def write_data(self):
        """
        Write the data to the target file path.

        This method copies the source file to the target file path and logs the operation.
        """
        source_path = os.path.join(self.data_dir, self.directory, self.file_name)
        shutil.copy(source_path, self.get_file_path())

        logger.info(f"{self._get_file_name_without_extension()} data written to file: {self.get_file_path()}")

    def get_dir_path(self):
        """
        Get the path to the target directory.

        :return: The path to the target directory.
        """
        return os.path.join(
            self.bin_dir,
            self.directory,
        )

    def get_file_path(self):
        """
        Get the full path to the target file.

        :return: The full path to the target file.
        """
        return os.path.join(
            self.get_dir_path(),
            f"{self.data_file_prefix} - {self.file_name}",
        )

    def _get_file_name_without_extension(self) -> str:
        """
        Get the file name without its extension.

        This method is used to log the file name without its extension for clarity.

        :return: The file name without its extension.
        """
        file_name_parts = os.path.basename(self.file_name)
        return os.path.splitext(file_name_parts)[0]

```
